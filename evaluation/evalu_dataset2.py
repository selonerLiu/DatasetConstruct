import datetime
import json
import os
import re
import time
from pathlib import Path
import yaml
from langchain_openai import ChatOpenAI


# 1.ä»æ–‡ä»¶ä¸­è¯»å–è¯•é¢˜åºåˆ—
def json_files_loader(input_dir=""):
    """
    åŠ è½½æ•°æ®é›†ï¼Œè¿™ä¸ªå‡½æ•°å¯ä»¥ç›´æ¥åŠ è½½ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å…¨éƒ¨jsonï¼Œå°±ä¸ç”¨å‰é¢é‚£ä¸ªåˆå¹¶çš„æ“ä½œäº†ã€‚
    :param input_dir: è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•
    :return: è¿”å›é—®é¢˜åˆ—è¡¨ï¼Œ
    """
    questions = []
    for filename in os.listdir(input_dir):
        if filename.endswith(".json"):
            file_path = os.path.join(input_dir, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                questions.extend(data)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(questions)} æ¡æ•°æ®")
    print(questions[0])
    return questions


# 2.è°ƒç”¨å¤§æ¨¡å‹å¯¹ç½®é”™æ–‡ä»¶è¿›è¡Œåˆ†æ
def get_model_answer(question, llm):
    """
    è°ƒç”¨å¤§æ¨¡å‹å¯¹å•ä¸ªé—®é¢˜ä½œç­”
    :param question: å•ä¸ªé—®é¢˜
    :return: å¤§æ¨¡å‹ä½œç­”ç»“æœï¼Œåªè¿”å›ä¸€ä¸ªç»“æœ
    """
    prompt = f"""
            Based on your knowledge of the theory and practice of automated formal analysis of cryptographic protocol security, 
            analyze the following formal model file delimited by "'''" to determine whether there are any errors. 
            Please provide a boolean answer (True or False) without any explanation. If there are errors, return True; if there are no errors, return False.:
            '''{question}'''
            """

    try:
        answer = llm.invoke(prompt).content

        if answer in ["True", "False"]:
            print(f"âœ… æ¨¡å‹è¿”å›æœ‰æ•ˆç­”æ¡ˆï¼š{answer}")
            return answer
        else:
            print(f"âš ï¸ æ¨¡å‹è¿”å›æ— æ•ˆç­”æ¡ˆï¼š{answer}")
            return answer  # è¡¨ç¤ºæ— æ•ˆç­”æ¡ˆ
    except Exception as e:
        print(f"âŒ è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼š{e}\n é‡æ–°å†è°ƒç”¨ä¸€é")
        return 0  # è¡¨ç¤ºé”™è¯¯


# 3.å…¨éƒ¨é—®é¢˜ä½œç­”ä¸ç»“æœå­˜å‚¨
def evaluate_dataset(all_formals, llmpara_file):
    """
    è°ƒç”¨å¤§æ¨¡å‹å¯¹å…¨éƒ¨é—®é¢˜è¿›è¡Œä½œç­”ï¼Œå¹¶å°†ç»“æœå’Œç›¸å…³çš„é‡è¦ä¿¡æ¯å­˜å‚¨åˆ°æ–‡ä»¶ä¸­
    :param all_formals:æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œè¿™é‡Œæˆ‘ä»¬åªè·å–æ–‡ä»¶çš„è·¯å¾„åˆ—è¡¨ï¼Œjsonæ–‡ä»¶ä¸­è¯»å–çš„åŒ…å«æ•°æ®é›†2å„ç§å‚æ•°çš„åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…æ‹¬ç½®é”™å½¢å¼åŒ–æ–‡ä»¶çš„åœ°å€ã€‚
    :param llmpara_file:è°ƒç”¨çš„å„ä¸ªå¤§æ¨¡å‹çš„å‚æ•°ä¿¡æ¯
    :return:è¿”å›å­—å…¸å‹çš„ç»“æœ
    """

    combined_data = []
    results_llms = []  # ç”¨ä¸€ä¸ªåˆ—è¡¨è¡¨ç¤ºæ‰€æœ‰å¤§æ¨¡å‹åšé¢˜çš„ç»“æœä¿¡æ¯ï¼Œåˆ—è¡¨æ¯ä¸€é¡¹çš„å†…å®¹æ˜¯ä¸€ä¸ªresultsåˆ—è¡¨ã€‚
    print(llmpara_file)
    with open(llmpara_file, "r", encoding="utf-8") as f:
        llmparameter_list = json.load(f)
    print(llmparameter_list[0])
    for item in llmparameter_list:
        print(f"ğŸ“Šæ­£åœ¨ä½¿ç”¨å¤§æ¨¡å‹{item['refer_model_name']}å¯¹è¯¥æ•°æ®é›†åšæµ‹è¯•è¯„ä¼°")
        llm = ChatOpenAI(model_name=item["refer_model_name"], openai_api_base=item["refer_api_base"],
                         openai_api_key=item["refer_api_key"])
        start_time = time.time()
        results = []  # ç”¨ä¸€ä¸ªåˆ—è¡¨å­˜å‚¨æŸä¸ªå¤§æ¨¡å‹äº§ç”Ÿçš„ç»“æœï¼Œåˆ—è¡¨å†…å®¹åŒ…æ‹¬é’ˆå¯¹å„é¢˜åšçš„ç»“æœï¼Œå’Œæ€»ç»“æœã€‚
        for i, single_formal in enumerate(all_formals):
            sigle_start_time = time.time()
            file_path = single_formal["dst_path"] # è¿™ä¸ªè·¯å¾„æ˜¯åˆ›å»ºçš„æ—¶å€™åœ¨dataset2_generatorè¿™ä¸ªæ–‡ä»¶å¤¹ä¸­å®ƒä»¬çš„ç›¸å¯¹è·¯å¾„ï¼Œåœ¨è¯„ä¼°æ–‡ä»¶å¤¹ä¸­ä½¿ç”¨è¿˜è¿›è¡Œä¿®æ”¹æ‰èƒ½è¯»å–åˆ°è¯¥æ–‡ä»¶ã€‚
            file_path = file_path.replace("../output/with_err_files", "../dataset2_generator/output/with_err_files")
            with open(file_path, "r", encoding='utf-8') as f:
                formal_content = f.read()
            print(f"ğŸ”„ æ­£åœ¨å¤„ç†ç¬¬{i + 1}ä¸ªæ•°æ®æ–‡ä»¶ï¼š{file_path}")
            is_result = 0
            while not(is_result): # é’ˆå¯¹ç”±äºç½‘ç»œæˆ–è°ƒç”¨æ¬¡æ•°é™åˆ¶å¯¼è‡´çš„è°ƒç”¨æ¨¡å‹å¤±è´¥å¤„ç†
                llm_result = get_model_answer(formal_content, llm)
                is_result = llm_result
            correct_answer = single_formal["has_err"]
            single_end_time = time.time()
            results.append({
                "id": i,
                "err_file": single_formal["dst_path"],
                "correct_answer": correct_answer,
                "model_answer": llm_result,
                "single_time_span": single_end_time - sigle_start_time,
                "is_result_correct": llm_result == correct_answer
            })
            print(f"âœ… å¤„ç†ç¬¬{i + 1}ä¸ªæ•°æ®æ–‡ä»¶å®Œæˆï¼Œç”¨æ—¶:{single_end_time - sigle_start_time}ç§’")
            # time.sleep(3)  # é˜²æ­¢è°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œå¯¼è‡´éƒ¨åˆ†é—­æºçš„åœ¨çº¿å¤§æ¨¡å‹è¢«ç¦æ­¢è®¿é—®
        end_time = time.time()
        time_span = end_time - start_time
        correct_num = sum(1 for result in results if result["is_result_correct"])
        summary_data = {
            "llm_name": item["refer_model_name"],
            "start_time": start_time,
            "end_time": end_time,
            "time_span": time_span,
        }
        combined_data = results + [summary_data]
        print(f"\nğŸ”„ åˆ†ææ€»æ•°ï¼š{len(results)}")
        print(f"âœ… æ€»ç”¨æ—¶ï¼š{time_span}")
        print(f"ğŸ¯ åˆ†ææ­£ç¡®ç‡ï¼š{correct_num/len(results):.2f}")
        print("ğŸ’å°†è¯¦ç»†ç»“æœå­˜è‡³æŒ‡å®šæ–‡ä»¶......................................\n\n")
        results_llms.append(combined_data)  # combined_dataæ˜¯ä¸€ä¸ªå¤§æ¨¡å‹å¯¹æ•°æ®é›†ä¸­æ‰€æœ‰æ–‡ä»¶æ‰§è¡Œçš„ç»“æœï¼Œresults_llmsç›¸å½“äºæ˜¯æ‰€æœ‰å¤§æ¨¡å‹çš„æ‰§è¡Œç»“æœã€‚
    return results_llms


def write2file(content, path_dir="", file_name="", file_type=""):
    results_dir = path_dir
    Path(results_dir).mkdir(parents=True, exist_ok=True)
    results_name = file_name
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    if file_type == "json":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"// å†™å…¥æ—¶é—´: {timestamp}\n\n")
            f.write(json.dumps(content, ensure_ascii=False, indent=4))
    elif file_type == "txt":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"[{timestamp}]\n\n{content}")
    elif file_type == "yaml":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"// å†™å…¥æ—¶é—´: {timestamp}\n\n")
            yaml.dump(content, f, allow_unicode=True)


def run(formal_file_dir="../dataset2_generator/output/test_set/",
        llms_para="../dataset1_rag_generator/config/refer_llms.json",
        result_directory="./results/dataset2/",
        prefix_filename="haserr_judge_", extension="json"):
    """
    è°ƒç”¨è¯„ä¼°å‡½æ•°ï¼Œå¹¶å°†è¯„ä¼°ç»“æœå­˜åˆ°æŒ‡å®šç›®å½•ä¸‹
    :param llms_para: è¯»å…¥ï¼Œå°†è¦ä½¿ç”¨çš„å¤§æ¨¡å‹å‚æ•°åˆ—è¡¨
    :param formal_file_dir: è¯»å…¥ï¼Œå½¢å¼åŒ–æ–‡ä»¶æ•°æ®é›†å‚æ•°çš„å­˜å‚¨ç›®å½•
    :param result_directory: è¾“å‡ºï¼Œæ–‡ä»¶å­˜å‚¨çš„ç›®å½•
    :param prefix_filename: è¾“å‡ºï¼Œæ–‡ä»¶å‘½åæ·»åŠ çš„åŒºåˆ«æ€§å‰ç¼€
    :param extension: è¾“å‡ºï¼Œæ–‡ä»¶çš„å­˜å‚¨æ ¼å¼
    :return: null
    """
    formal_file_para = json_files_loader(formal_file_dir)  # è¯»å–ç›®å½•ä¸‹çš„æ‰€æœ‰jsonæ–‡ä»¶ï¼Œåªæœ‰ä¸€ä¸ªæ–‡ä»¶æ—¶ä¹Ÿå¯ä»¥
    all_llms_results = evaluate_dataset(formal_file_para, llms_para)  # ä½¿ç”¨llms_paraä¸­ä¸åŒçš„å¤§æ¨¡å‹å¯¹formal_file_paraä¸­çš„å„ä¸ªæ–‡ä»¶è¿›è¡Œè¯„ä¼°
    # è¯„åˆ¤å®Œæ¯•åå°†ç»“æœå­˜å‚¨åˆ°æŒ‡å®šæ–‡ä»¶ä¸­ï¼Œæ–‡ä»¶ç›®å½•æ˜¯result_directoryï¼Œæ–‡ä»¶å‘½åä¸ºåˆ¤å®šç±»å‹+å¤§æ¨¡å‹åç§°
    for index, one_llm_result in enumerate(all_llms_results):
        print(f"ğŸ”„ æ­£åœ¨å­˜å‚¨ç¬¬{index + 1}ä¸ªå¤§æ¨¡å‹çš„ç»“æœ")
        try:
            write2file(content=one_llm_result,
                       path_dir=result_directory,
                       file_name=prefix_filename + one_llm_result[-1]["llm_name"],
                       file_type=extension)
        except Exception as e:
            print(f"å­˜å‚¨txtæ–‡ä»¶å‘ç”Ÿé”™è¯¯ï¼š{e}")


if __name__ == "__main__":
    # # ä½¿ç”¨æµ‹è¯•æ–‡ä»¶å’Œæµ‹è¯•å¤§æ¨¡å‹ï¼Œæµ‹è¯•æ€»ä½“è¿‡ç¨‹ã€‚
    # run(formal_file_dir="../dataset2_generator/output/test_set/",
    #     llms_para="../dataset1_rag_generator/config/test_llms.json",
    #     result_directory="./results/dataset2/",
    #     prefix_filename="haserr_judge_", extension="json")

    # ä½¿ç”¨å®é™…æ–‡ä»¶å’Œå®é™…æµ‹è¯„æ¨¡å‹ï¼Œè¿è¡Œæ€»ä½“è¿‡ç¨‹
    run(formal_file_dir="../dataset2_generator/output/dataset_remote/",
        llms_para="../dataset1_rag_generator/config/test_llms.json",
        result_directory="./results/dataset2/",
        prefix_filename="haserr_judge_", extension="json")
