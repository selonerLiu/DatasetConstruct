import json
from tqdm import tqdm
from langchain_openai import ChatOpenAI
import time
from pathlib import Path
import yaml
import datetime
import os

def answer_format(res_str):
    return res_str


def response_compare(response, benchmark):
    # åˆ¤æ–­æ˜¯å¦ä¸€ä¸ªå®Œæ•´çš„å½¢å¼åŒ–è¡¨è¾¾å¼
    if response == benchmark:
        # å¦‚æœæ˜¯å®Œæ•´è¡¨è¾¾å¼å†è¿›è¡Œä¸‹ä¸€æ­¥åˆ¤æ–­å†…å®¹çš„ç›¸ä¼¼ç¨‹åº¦ï¼Œè¿”å›ä¸€ä¸ªç›¸ä¼¼å€¼ï¼Œå®Œå…¨ç›¸åŒä¸º1
        return 1
    # å¦‚æœä¸æ˜¯å®Œæ•´å½¢å¼åŒ–è¡¨è¾¾å¼ï¼Œåˆ™è¿”å›0
    else:
        return 0    

# 1.åŠ è½½å‡†å¤‡ä½¿ç”¨å¤§æ¨¡å‹å¤„ç†çš„æ•°æ®é›†
def json_files_loader(input_dir=""):
    """
    åŠ è½½æ•°æ®é›†ï¼Œè¿™ä¸ªå‡½æ•°å¯ä»¥ç›´æ¥åŠ è½½ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸‹çš„å…¨éƒ¨jsonï¼Œå°±ä¸ç”¨å‰é¢é‚£ä¸ªåˆå¹¶çš„æ“ä½œäº†ã€‚
    :param input_dir: è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•
    :return: è¿”å›é—®é¢˜åˆ—è¡¨ï¼Œ
    """
    questions = []
    for filename in os.listdir(input_dir):
        if filename.endswith(".json"):
            file_path = os.path.join(input_dir, filename)
            with open(file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                questions.extend(data)
    print(f"âœ… æˆåŠŸåŠ è½½ {len(questions)} æ¡æ•°æ®")
    return questions


# 2.è°ƒç”¨å¤§æ¨¡å‹å¯¹ç½®é”™æ–‡ä»¶è¿›è¡Œåˆ†æ
def get_model_answer(instance, llm):
    """
    è°ƒç”¨å¤§æ¨¡å‹å¯¹å•ä¸ªé—®é¢˜ä½œç­”
    :param instance: jsonæ•°æ®é›†æ–‡ä¸­çš„å•ä¸ªå®ä¾‹
    :llm: åˆ†æå½“å‰å®ä¾‹ä½¿ç”¨çš„å¤§æ¨¡å‹
    :return: å¤§æ¨¡å‹ä½œç­”ç»“æœï¼Œåªè¿”å›ä¸€ä¸ªç»“æœ
    """
    instruction = instance['instruct']
    nl_input = instance['input']
    prompt = instruction + nl_input + "the result you output should not include redundant information only reserve the formal expressions"
    try:
        answer = llm.invoke(prompt).content
        if answer in ["True", "False"]:
            print(f"âœ… æ¨¡å‹è¿”å›æœ‰æ•ˆç­”æ¡ˆï¼š{answer}")
            return answer
        else:
            print(f"âš ï¸ æ¨¡å‹è¿”å›æ— æ•ˆç­”æ¡ˆï¼š{answer}")
            return f"âš ï¸ æ¨¡å‹è¿”å›æ— æ•ˆç­”æ¡ˆï¼š{answer}"  # è¡¨ç¤ºæ— æ•ˆç­”æ¡ˆ
    except Exception as e:
        print(f"âŒ è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼š{e}")
        return f"âŒ è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼š{e}"  # è¡¨ç¤ºé”™è¯¯


# 3.å…¨éƒ¨å¤§æ¨¡å‹å¯¹å…¨éƒ¨æ•°æ®é›†ç¿»è¯‘ç»“æœåŠå­˜å‚¨
def evaluate(data_list, llmpara_list):
    """
    è°ƒç”¨æœ¬åœ°æ¨¡å‹ï¼Œå®Œæˆç¿»è¯‘ï¼Œç„¶åæ¯”å¯¹ç»“æœ
    """
    all_llm_results=[]
    for llmpara in llmpara_list:
        one_llm_result = []
        print(f"ğŸ“Š  å¼€å§‹æµ‹è¯•å¤§æ¨¡å‹{llmpara["refer_model_name"]}åœ¨æ•°æ®é›†3ä¸Šçš„ç¿»è¯‘èƒ½åŠ›")
        start_time = time.time()
        llm_inst = ChatOpenAI(model_name=llmpara["refer_model_name"], openai_api_base=llmpara["refer_api_base"], openai_api_key=llmpara["refer_api_key"])
        for index, instance in enumerate(data_list):
            correct = 0
            total = 0
            print(f"ğŸ”„  è¿›å…¥å®ä¾‹{index}: {instance}ç¿»è¯‘èƒ½åŠ›æµ‹è¯•")
            single_start_time = time.time()
            retry = True
            while retry:
                response = get_model_answer(instance, llm_inst)
                print(f"é’ˆå¯¹\'{instance}\'\nå¤§æ¨¡å‹ç»™å‡ºçš„å½¢å¼åŒ–ç¿»è¯‘æ˜¯ï¼š" + response)
                # åˆ¤æ–­è¿”å›ç»“æœæ˜¯å¦ç¬¦åˆé€‰é¡¹æ ¼å¼è¦æ±‚ï¼Œè¿™ä¸ªè¿”å›ç»“æœåº”å½“åªæœ‰ä¸€è¡Œï¼Œä¸”è¿™ä¸€è¡Œä¹Ÿåªæœ‰å½¢å¼åŒ–è¡¨è¾¾å¼
                formated_response = answer_format(response)
                # å¦‚æœè¿”å›çš„å†…å®¹æ˜¯æƒ³è¦çš„ç­”æ¡ˆæ ·å¼ï¼Œå°±å°†retryç½®å¦ï¼Œè¿™èƒ½ä½¿ç¨‹åºè·³å‡ºwhileå¾ªç¯è¿›å…¥ä¸‹ä¸€ä¸ªé—®é¢˜çš„å¤„ç†ã€‚
                if formated_response:
                    print("æ­¤ç­”æ¡ˆæ ¼å¼ç¬¦åˆé¢„æœŸï¼Œè®¡ç®—å†…å®¹ç›¸ä¼¼åº¦")
                    compa_result = response_compare(formated_response, instance['output'])
                    correct += compa_result
                    total += 1
                    retry = False
                # å¦‚æœè¿”å›çš„ç­”æ¡ˆä¸ç¬¦åˆæ ¼å¼è¦æ±‚ï¼Œä¿®æ”¹promptï¼Œå†è®©å¤§æ¨¡å‹å¤„ç†ä¸€éè¿™ä¸ªç»“æœ
                else:
                    print("æ­¤ç­”æ¡ˆä¸æ ¼å¼ä¸ç¬¦åˆé¢„æœŸæ ¼å¼ï¼Œä¿®æ”¹prompté‡æ–°å†å¤„ç†ä¸€éå½“å‰question")
                    prompt = prompt + "\n\n" + response + "the response is not a specification only use the proverif model language"
            single_end_time = time.time()
            single_time_span = single_end_time-single_start_time
            one_llm_result.append({
                "instance_num": index,
                "raw_nl_spec": instance["input"],
                "llm_resp": response,
                "prcesed_resp": formated_response,
                "is_correct": compa_result,
                "accuracy": correct/total,
                "single_time_span": single_time_span
            })
        end_time = time.time()
        all_time_span = end_time-start_time
        summary_data = {
            "llm_name": llmpara["refer_model_name"],
            "start_time": start_time,
            "end_time": end_time,
            "time_span": all_time_span,
        }
        combined_data = one_llm_result + [summary_data]
        all_llm_results.append(combined_data)
        print(f"\nğŸ”„ åˆ†ææ€»æ•°ï¼š{len(one_llm_result)}")
        print(f"âœ… æ€»ç”¨æ—¶ï¼š{all_time_span}")
        print("ç›¸ä¼¼åº¦æ€»å’Œä¸ºï¼š" + str(correct) + "\nå‚ä¸è¯„ä¼°å®ä¾‹æ•°ä¸ºï¼š" + str(total))
        print("ğŸ’å°†è¯¦ç»†ç»“æœå­˜è‡³æŒ‡å®šæ–‡ä»¶......................................\n\n")
    return all_llm_results


def write2file(content, path_dir="", file_name="", file_type=""):
    results_dir = path_dir
    Path(results_dir).mkdir(parents=True, exist_ok=True)
    results_name = file_name
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    if file_type == "json":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"// å†™å…¥æ—¶é—´: {timestamp}\n\n")
            f.write(json.dumps(content, ensure_ascii=False, indent=4))
    elif file_type == "txt":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"[{timestamp}]\n\n{content}")
    elif file_type == "yaml":
        with open(f"{results_dir}/{results_name}.{file_type}", "w", encoding="utf-8") as f:
            f.write(f"// å†™å…¥æ—¶é—´: {timestamp}\n\n")
            yaml.dump(content, f, allow_unicode=True)


def run(dataset_dir, llm_path, result_directory, prefix_filename, extension):
    # è¯»å–æ•°æ®é›†åˆ—è¡¨
    data_list = json_files_loader(dataset_dir)
    # è¯»å–å¤§åˆ—è¡¨
    with open(llm_path, "r", encoding="utf-8") as f:
        llmparameter_list = json.load(f)
    # å¼€å§‹ç”¨ä¸åŒå¤§æ¨¡å‹å¯¹æ•°æ®é›†åˆ—è¡¨ä¸­çš„æ•°æ®è¿›è¡Œè¯„ä¼°
    allm_results = evaluate(data_list, llmparameter_list)
    # å­˜å‚¨æ•°æ®
    for one_llm_result in allm_results:
        try:
            write2file(content=one_llm_result,
                       path_dir=result_directory,
                       file_name=prefix_filename + one_llm_result[-1]["llm_name"],
                       file_type=extension)
        except Exception as e:
            print(f"å­˜å‚¨txtæ–‡ä»¶å‘ç”Ÿé”™è¯¯ï¼š{e}")


if __name__ == "__main__":
    run(dataset_dir="./dataset3_reverse_generator/test_set/",
        llm_path="./dataset1_rag_generator/config/test_llms.json",
        result_directory="./results/dataset3/",
        prefix_filename="translate_", extension="json")
    # print(type(response_compare("abc","123")))
